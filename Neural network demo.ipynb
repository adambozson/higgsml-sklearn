{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network demo\n",
    "This notebook demonstrates the use of a neural network built and trained with _[Keras](http://keras.io)_ with the higgsml dataset and some features of the scikit-learn library.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data\n",
    "Import the required data and split into features, class labels, and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/atlas-higgs-challenge-2014-v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = (df['Label'] == 's').astype(int)\n",
    "weights = df['Weight']\n",
    "data = df.drop(['EventId', 'Weight', 'Label', 'KaggleSet', 'KaggleWeight'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data\n",
    "Split into 50% train/test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(data, classes, weights, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reweight the training samples to equal importance for signal and background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reweight = lambda w: w / (2 * w.sum())\n",
    "w_train_normed = w_train.groupby(y_train).transform(reweight) * w_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features to remove the mean and have unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define and train neural network\n",
    "For a simple single-layer perceptron, use the `Sequential` model from Keras with one layer after the input and a single-node output. Note that the first call to `model.add` defines both the input and hidden layers. The hidden layer has 10 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 10)            310         dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             11          dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 321\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the binary cross-entropy as the loss function, and the Adam optimisation algorithm with default configuration. In the training step, tell Keras to use 20% of the data for testing between epochs. Note that this means we are using a nested cross-validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327295 samples, validate on 81824 samples\n",
      "Epoch 1/10\n",
      "327295/327295 [==============================] - 5s - loss: 0.4202 - val_loss: 0.3838\n",
      "Epoch 2/10\n",
      "327295/327295 [==============================] - 5s - loss: 0.3793 - val_loss: 0.3665\n",
      "Epoch 3/10\n",
      "327295/327295 [==============================] - 5s - loss: 0.3652 - val_loss: 0.3544\n",
      "Epoch 4/10\n",
      "327295/327295 [==============================] - 5s - loss: 0.3565 - val_loss: 0.3485\n",
      "Epoch 5/10\n",
      "327295/327295 [==============================] - 5s - loss: 0.3516 - val_loss: 0.3442\n",
      "Epoch 6/10\n",
      "327295/327295 [==============================] - 5s - loss: 0.3488 - val_loss: 0.3443\n",
      "Epoch 7/10\n",
      "327295/327295 [==============================] - 5s - loss: 0.3470 - val_loss: 0.3408\n",
      "Epoch 8/10\n",
      "327295/327295 [==============================] - 5s - loss: 0.3458 - val_loss: 0.3403\n",
      "Epoch 9/10\n",
      "327295/327295 [==============================] - 5s - loss: 0.3447 - val_loss: 0.3407\n",
      "Epoch 10/10\n",
      "327295/327295 [==============================] - 5s - loss: 0.3437 - val_loss: 0.3382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2548afe310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          nb_epoch=10,\n",
    "          verbose=1,\n",
    "          validation_split=.2,\n",
    "          sample_weight=w_train_normed.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate trained model\n",
    "The Keras model can bne used with scikit-learn functions to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87565334826750862"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_hat = model.predict(X_test)\n",
    "roc_auc_score(y_test, y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
